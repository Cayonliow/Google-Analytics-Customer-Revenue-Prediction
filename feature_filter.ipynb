{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import sys\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from plotly import tools\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from sklearn import model_selection, preprocessing, metrics\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(csv_path='./data/train1000.csv', nrows=None):\n",
    "    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "    \n",
    "    df = pd.read_csv(csv_path, \n",
    "                     converters={column: json.loads for column in JSON_COLUMNS}, \n",
    "                     dtype={'fullVisitorId': 'str'}, # Important!!\n",
    "                     nrows=nrows)\n",
    "    \n",
    "    for column in JSON_COLUMNS:\n",
    "        column_as_df = json_normalize(df[column])\n",
    "        column_as_df.columns = [column + '.' + subcolumn for subcolumn in column_as_df.columns]\n",
    "        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_COLUMNS_NEST = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "JSON_COLUMNS_NEST_SINGLE = ['channelGrouping', 'visitNumber', 'visitStartNumber']\n",
    "\n",
    "total_fea = ['pageviews', 'hits']\n",
    "traffic_fea = ['medium','keyword', 'source', 'referralPath', 'isTrueDirect']\n",
    "geo_fea = ['networkDomain','city','metro','region','country','continent','subContinent']\n",
    "device_fea = ['deviceCategory','operatingSystem', 'browser']\n",
    "fea = { 'device': device_fea, 'geoNetwork': geo_fea, 'totals': total_fea, 'trafficSource': traffic_fea}\n",
    "\n",
    "csv_path='./data/train1000.csv'\n",
    "extract_csv = './data/train_extract.csv'\n",
    "\n",
    "with open(csv_path) as fp:  \n",
    "    reader = csv.reader(fp)\n",
    "    row1 = next(reader)\n",
    "    df = pd.DataFrame(columns=row1)\n",
    "    \n",
    "    count = 0\n",
    "    while(count < 10):\n",
    "        missing=0\n",
    "        dic = {}\n",
    "        \n",
    "        row = next(reader)\n",
    "        row_standby = row.copy()\n",
    "        d = json.dumps(row)\n",
    "        g = json.loads(d)\n",
    "\n",
    "        for col in row1:\n",
    "            if col in JSON_COLUMNS_NEST:\n",
    "                subobj = json.loads(row[row1.index(col)])\n",
    "                for _, feat in enumerate(fea[col]):\n",
    "                    try:\n",
    "                        if subobj[feat] == 'not available in demo dataset' or subobj[feat] =='(not set)':\n",
    "                            dic[str(col+ '.'+ feat)] = subobj[feat]\n",
    "                            missing+=1\n",
    "                    except KeyError as error:\n",
    "                        missing+=1\n",
    "        if missing < 10:\n",
    "            df.loc[count] = row\n",
    "            count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['channelGrouping', 'customDimensions', 'date', 'device',\n",
      "       'fullVisitorId', 'geoNetwork', 'hits', 'socialEngagementType', 'totals',\n",
      "       'trafficSource', 'visitId', 'visitNumber', 'visitStartTime'],\n",
      "      dtype='object')\n",
      "channelGrouping         object\n",
      "customDimensions        object\n",
      "date                     int64\n",
      "device                  object\n",
      "fullVisitorId           object\n",
      "geoNetwork              object\n",
      "hits                    object\n",
      "socialEngagementType    object\n",
      "totals                  object\n",
      "trafficSource           object\n",
      "visitId                  int64\n",
      "visitNumber              int64\n",
      "visitStartTime           int64\n",
      "dtype: object\n",
      "8934116514970143966\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.columns)\n",
    "dataframe = dataframe.astype({\"date\": int, \"visitId\": int, \"visitNumber\": int, 'visitStartTime': int})\n",
    "print(dataframe.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
